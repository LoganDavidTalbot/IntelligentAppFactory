{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"about/","title":"Welcome","text":"<p>Intelligent App Factory is open-source project provides detailed insights into how Intelligent Apps can be secured, developed, and architected at scale. Aiming to Empower, Educate, and Innovate the developer community and enterprises in the field of Intelligent Apps.</p> <p>While the current focus is on Azure solutions, we plan to expand to other hyper-scalers in the future.</p>"},{"location":"about/#our-goals","title":"Our Goals","text":"<ul> <li> Aggregate information from various sources and present it in a user-friendly manner.</li> <li> Prioritize the perspective of the contemporary Enterprise application developer and solution architect. The scope includes the development and production of intelligent apps, the prompting and fine-tuning of LLMs, and the use of AI cloud services, but does not extend to the training of new models.</li> <li> Creation of a 'factory' to scale the learning and development of intelligent applications for organizations and individuals.</li> <li> Promote the use of sustainable and ethical AI practices in the development of intelligent applications.</li> </ul>"},{"location":"about/#our-values","title":"Our Values","text":"<p>Our values guide our actions and decisions as we strive to succeed our goals and deliver exceptional experiences to our community members:</p> <p>-[x] Empowerment: We empower individuals and organizations to harness the power of intelligent apps and AI technologies to achieve their goals. -[x] Education: We are committed to providing educational resources and training opportunities to help individuals and organizations build their skills in developing intelligent apps. -[x] Innovation: We are committed to driving innovation in the field of intelligent applications, pushing the boundaries of what is possible and exploring new possibilities. -[x] Community: We actively engage with the developer community, sharing knowledge and collaborating to drive innovation in the field of intelligent applications. -[x] Responsibility: We take responsibility for the impact of our intelligent applications on society, ensuring that they are used ethically and responsibly. -[x] Agility: We embrace change and adapt quickly to evolving market trends and community demands.</p>"},{"location":"about/#content","title":"Content","text":"<ul> <li> <p> Getting Started</p> <p>Learn how to develop, design, and manage Intelligent Apps.</p> <p> View</p> </li> <li> <p> Components</p> <p>Explore the different components of an Intelligent App.</p> <p> View</p> </li> <li> <p> Concepts</p> <p>Explore the different components of an Intelligent App.</p> <p> View</p> </li> <li> <p> Well-architected</p> <p>Learn how to design and deploy well-architected Intelligent Apps.</p> <p> View</p> </li> <li> <p> Reference Architecture</p> <p>Explore the different reference architectures for Intelligent Apps.</p> <p> View</p> </li> </ul>"},{"location":"about/#core-team-contributors","title":"Core Team &amp; Contributors","text":"<ul> <li>Logan Talbot, Tech Lead &amp; Senior Solution Architect @ Capgemini</li> </ul>"},{"location":"certifications/","title":"Recommended Certifications for Intelligent Applications","text":"<p>Certifications are a great way to demonstrate your expertise in a particular technology or domain. They are also a great way to learn new skills and stay up-to-date with the latest trends in the industry. In this guide, we will recommend some certifications that are relevant to building intelligent applications. This includes focus on cloud-native and AI certifications from major cloud providers like Microsoft, AWS, and Google Cloud, as well as certifications related to Kubernetes.</p>"},{"location":"certifications/#iafs-recommended-certifications","title":"IAF's Recommended Certifications","text":"<p>In each tab below, we have listed some of the most relevant certifications for building intelligent applications. We have categorized them based on the provider, focus area, level, and priority. The priority is based on the relevance of the certification to building intelligent applications. Certifications with a higher priority are more relevant and should be pursued first. Certifications marked with optional are not mandatory but can be pursued if you are interested in the topic. </p> <p>Level indicates the difficulty level of the certification, with beginner being the easiest, and advanced being the hardest. Current professionals may want to start with intermediate or advanced certifications, while beginners may want to start with beginner certifications.</p> Azure CertificationsAWS CertificationsGoogle Cloud CertificationsKubernetes Certifications Certification Provider Focus Level Priority Microsoft Certified: Azure Fundamentals Microsoft Cloud Native Beginner Optional Microsoft Certified: AI Fundamentals Microsoft AI Beginner Optional Microsoft Certified: Azure Developer Associate Microsoft Cloud Native Intermediate Priority 1 Microsoft Certified: Azure AI Engineer Associate Microsoft AI Intermediate Priority 1 Microsoft Certified: Azure DevOps Engineer Expert Microsoft Cloud Native Advanced Priority 2 Microsoft Certified: Azure Solutions Architect Expert Microsoft Cloud Native Advanced Priority 2 Microsoft Certified: Azure Developer Associate Microsoft Cloud Native Intermediate Priority 2 Microsoft Certified: Azure Security Engineer Associate Microsoft Security Intermediate Priority 3 Microsoft Certified: Security Architect Expert Microsoft Security Advanced Priority 3 Certification Provider Focus Level Priority AWS Certified Cloud Practitioner AWS Cloud Native Beginner Optional AWS Certified Developer - Associate AWS Cloud Native Intermediate Priority 1 AWS Certified Machine Learning - Specialty AWS AI Intermediate Priority 1 AWS Certified Solutions Architect - Associate AWS Cloud Native Intermediate Priority 1 AWS Certified Solutions Architect - Professional AWS Cloud Native Advanced Priority 2 AWS Certified DevOps Engineer - Professional AWS DevOps Advanced Priority 2 AWS Certified Security - Specialty AWS Security Intermediate Priority 3 Certification Provider Focus Level Priority Google Cloud Associate Cloud Engineer Google Cloud Cloud Native Intermediate Priority 1 Google Cloud Certified Professional Developer Google Cloud Development Intermediate Priority 1 Google Cloud Professional Machine Learning Engineer Google Cloud AI Intermediate Priority 1 Google Cloud Professional Cloud Architect Google Cloud Cloud Native Advanced Priority 2 Google Cloud Professional DevOps Engineer Google Cloud DevOps Advanced Priority 2 Google Cloud Professional Security Engineer Google Cloud Security Advanced Priority 3 Certification Provider Focus Level Priority Certified Kubernetes Application Developer (CKAD) CNCF Kubernetes Intermediate Priority 2"},{"location":"community/","title":"Join our community","text":"<p>We have a community of developers and users who are happy to help you with your questions, ideas, and feedback. Join us on our community platforms to engage with other members, share your experiences, and stay up-to-date with the latest news and updates.</p> <ul> <li> <p> Discord</p> <p>Join our Discord server to chat with other members, ask questions, and join events.</p> <p> Join</p> </li> <li> <p>/ Stay in the know</p> <p>Follow us on Twitter/ X.com to stay up-to-date with the latest news, updates, and announcements.</p> <p> Follow</p> </li> <li> <p> Medium</p> <p>Follow our Medium publication to read articles, tutorials, and guides on cloud-native intelligent applications.</p> <p> View posts</p> </li> <li> <p> Youtube</p> <p>Subscribe to our YouTube channel to watch videos, tutorials, and webinars on intelligent applications.</p> <p> View posts</p> </li> </ul>"},{"location":"design-principles/","title":"Design principles for Intelligent Applications","text":"<p>The design principles for intelligent applications are based on the Well-Architected Framework, which provides a consistent approach for customers and partners to evaluate architectures and implement designs that will scale over time. The framework consists of a set of questions, known as the pillars, which are designed to help you think about architectural decisions throughout the lifecycle of your projects. The framework also provides a set of design principles that are used to guide the decision-making process when designing and implementing solutions.</p> <ol> <li>Intelligent Applications are still cloud native applications.</li> </ol>"},{"location":"intelligent-app-lifecycle/","title":"Intelligent Application Lifecycle","text":"<p>The lifecycle of an intelligent application borrows elements from both the cloud-native application and LLM application lifecycles. It is an iterative process that involves exploring, building, augmenting, improving, optimizing, and managing intelligent applications. This lifecycle is specifically designed to assist intelligent app delivery teams and organizations in creating, deploying, and managing cloud-native applications. These applications leverage large language models (LLMs) and AI services to deliver value to end users.</p> <p></p> <p>The lifecycle of an intelligent application includes the following iterative steps:</p> <ul> <li>Explore: Create proof of concepts and prototypes to validate their ideas and hypotheses but also to understand the capabilities and limitations of the chosen technologies.</li> <li>Build &amp; Augment: Develop the core features of the intelligent application. This including implementing security and observability features, and looking to increase the AI augmentation the model to better meet the business specific needs with such techniques as retrieval augmented generation (RAG), fine tuning and prompt engineering.</li> <li>Improve &amp; Optimize: Transition from development to production. This phase primarily involves deploying to a production-like environment, enhancing monitoring, incorporating content safety systems, and ensuring full integration of DevOps capabilities, including CI/CD. This phase is crucial for ensuring continuous feedback from the application itself and the end users to ensure the continuation of business value is still provided over lifetime of the application.</li> <li>Management &amp; Oversight: Working in parallel to all other phase involves an structured framework to development and evaluation of Intelligent Applications. Ensuring the correct governance, management, and security of the application.</li> </ul>"},{"location":"intelligent-app-lifecycle/#explore","title":"Explore","text":"<p>In this initial iterative phase, either a single developer or a team of developers aim to explore and experiment with a range of cloud and AI capabilities to identify the best technology choices for their specific business needs. They work on creating proof of concepts and prototypes to validate their ideas and hypotheses, and to understand the capabilities and limitations of the technology.</p> <p>A good example of this is working with a subset of data and prompts, trying to understand the capabilities and limitations of a range of LLM models through prototyping and evaluation. This exploration involves altering prompts to the models, experimenting with different chunking sizes and vector indexing methods, and conducting basic interactions while trying to validate or refute business hypotheses.</p> <p>This phase is repeated until the team has a clear understanding of the capabilities and limitations of the technology and has validated their business hypotheses, thereby ensuring that the business needs can be met.</p>"},{"location":"intelligent-app-lifecycle/#build-augment","title":"Build &amp; Augment","text":"<p>Once a delivery team has a clear understanding of the capabilities and limitations of the technology, they move Build &amp; Augment iterative phrase which focuses on guiding and enhancing the technology to better meet the business specific needs making the application more feature rich and useable for the targeted end users. This is where core development work of an intelligent application including taking an everything as code approach to development, testing, and the creation of the application's infrastructure. As well as looking to hardening the security and observability of the application. </p> <p>From an LLM feature perspective, this may include look to fine tune the model to better align the system\u2019s responses with the specific requirements of the task at hand, but in the most case looking to provide better prompting or the implementation of a retrieval augmented generation (RAG) approach to inject information from internal or external data sources into the prompt based on the specific user request.</p>"},{"location":"intelligent-app-lifecycle/#improve-optimize","title":"Improve &amp; Optimize","text":"<p>This is the final iterative phase of the intelligent application lifecycle, which aims to transition from development to production. This phase primarily involves deploying to a production-like environment, enhancing monitoring, incorporating content safety systems, and ensuring full integration of DevOps capabilities, including CI/CD (continuous integration and continuous deployment) processes, if not already in place.</p> <p>Assuming the correct governance, management, and security of the application are in place, the application is ready to be deployed to production. The intelligent application should be ready to be improved and optimized, a continuous feedback loop needs to be established with several sources crucial to providing a comprehensive view of the application's performance and user experience. This includes monitoring the application's performance and outputs, gathering user feedback, and assessing the application's ability to meet business needs. This phase is crucial for ensuring that the intelligent application continues to provide value over time and adapts to changing needs and conditions. This allows your intelligent application to react quickly to changing business needs or potential issues.</p> <p>The only way to escape of this phase to go back to the previous phase of 'Build &amp; Augment' or for the application to be decommissioned.</p>"},{"location":"intelligent-app-lifecycle/#management-oversight","title":"Management &amp; Oversight","text":"<p>This phase is a continuous process of management and oversight of the deployed application which works in parallel to all other phase. This involved ensuring an structured framework to development and evaluation of Intelligent Applications. Ensuring the correct governance, management, and security of the application. This phase is crucial for ensuring that the intelligent application continues to provide value over time and adapts to changing needs and conditions.</p> <p>It is important that as part of this phase your intelligent application adhere to the best practices for responsible AI and data governance. This includes ensuring that the application is secure, compliant with regulations, and respects user privacy. By following these best practices, organizations can build trust with their users and stakeholders and ensure the long-term success of their intelligent applications.</p>"},{"location":"intelligent-app-lifecycle/#sources","title":"Sources","text":"<ul> <li>The New Stack: The Cloud-Native Application Lifecycle Difference: Continuous Change</li> <li>Microsoft Azure Blog: Building for the future: The enterprise generative AI application lifecycle with Azure AI</li> </ul>"},{"location":"news-archive/","title":"Interesting News Articles for Intelligent Apps","text":""},{"location":"news-archive/#ai-wins","title":"AI Wins","text":"<ul> <li> <p>Klarna AI assistant handles two-thirds of customer service chats in its first month</p> <p>Klarna today announced its AI assistant powered by OpenAI. Now live globally for 1 month. The AI assistant has had 2.3 million conversations, two-thirds of Klarna\u2019s customer service chats. It is doing the equivalent work of 700 full-time agents. It is on par with human agents in regard to customer satisfaction score</p> <p> Link</p> </li> <li> <p>Duolingo cuts 10% of its contractor workforce as the company embraces AI</p> <p>Duolingo is the latest company to cite AI as a reason for job cuts. The company confirmed it cut around 10% of its contractor workforce at the end of 2023, as it turns to AI models like OpenAI\u2019s GPT-4 to streamline content production and translations.</p> <p> Link</p> </li> </ul>"},{"location":"news-archive/#ai-loses","title":"AI Loses","text":"<ul> <li> <p>AI fired nukes in a war simulation because it wanted 'peace in the world'</p> <p>OpenAI\u2019s GPT models sounded like a genocidal dictator in a test of war-time decision-making.</p> <p> Link</p> </li> <li> <p>Air Canada chatbot promised a discount. Now the airline has to pay it.</p> <p>Air Canada argued the chatbot was a separate legal entity \u2018responsible for its own actions,\u2019 a Canadian tribunal said.</p> <p> Link</p> </li> </ul>"},{"location":"news-archive/#research","title":"Research","text":"<ul> <li> <p>Demand Grows for Intelligent Applications Powered by AI</p> <ul> <li>Any software application can seem smart, but intelligent apps actually are.</li> <li>They can learn, adapt, generate new ideas and outcomes and increase automated and dynamic decision making.</li> </ul> <p> Link</p> </li> <li> <p>AI in the Enterprise: The AI Adoption Report 2022</p> <p>The AI Adoption Report 2022 is a comprehensive study of AI adoption in the enterprise. The report is based on a survey of 1,000 business and technology leaders from around the world. The report provides insights into the current state of AI adoption, the challenges and opportunities that organizations face, and the strategies that are driving success.</p> <p> Link</p> </li> <li> <p>Exploring the Rapidly Growing Intelligent Apps Market: Trends and Insights</p> <p>The intelligent apps market is a rapidly growing segment of the software industry. According to a report by Straits Research, the global intelligent apps market size is expected to reach USD 182.3 billion by 2031, growing at a compound annual growth rate (CAGR) of 31.7 % during the forecast period of 2023-2031.</p> <p> Link</p> </li> <li> <p>Top Artificial Intelligence Statistics and Facts for 2024</p> <p>Here are some top AI statistics to help you understand AI usage in 2024 \u2013 and beyond.</p> <p>February 29, 2024     Link</p> </li> </ul>"},{"location":"resources/","title":"Resources","text":""},{"location":"resources/#github-repositories","title":"GitHub Repositories","text":"<ul> <li>Azure - AI in a box</li> <li>Azure - Vector Search &amp; AI Assistant for Azure Cosmos DB for MongoDB vCore</li> <li>Azure - AzureChat</li> <li>Microsoft  - azure openai design patterns</li> <li>Microsoft - Azure Samples for Retrieval-Augmented LLMs with Azure Data (C# &amp; Python)</li> <li> Azure - Vector Search &amp; AI Assistant for Azure Cosmos DB and Azure Cognitive Search (aka Bring Your Data to ChatGPT)</li> </ul>"},{"location":"resources/#reading-list","title":"Reading list","text":"<ul> <li>Building for the future: The enterprise generative AI application lifecycle with Azure AI</li> <li>Demystifying Retrieval Augmented Generation with .NET</li> <li>MicroAgents: Exploring Agent Architecture with Microservices</li> <li>Martin Fowler - Engineering Practices for LLM Application Development</li> <li>Azure Architecture Blog - Azure OpenAI Landing Zone reference architecture</li> </ul>"},{"location":"resources/#youtube-playlist","title":"YouTube Playlist","text":"<ul> <li>Microsoft Reactor Series, GenAI for Software Developer</li> </ul>"},{"location":"responsible-ai/","title":"Responsible AI for Intelligent Apps","text":""},{"location":"security/","title":"Security for Intelligent App","text":"<p>The security of an Intelligent App should be built on a zero-trust approach, incorporating principles of confidentiality, integrity, and availability (CIA triad). It's crucial to understand the potential impact of security incidents on the business and to have measures in place to limit the damage.</p> <p>Key considerations include:</p> <ul> <li>Ensuring defensive investments deter attackers and limit the impact of any security breach.</li> <li>Understanding the potential value of the workload to an attacker and the business impact of data theft, unavailability, or tampering.</li> <li>The ability to quickly detect, respond to, and recover from disruptions.</li> </ul> <p>A Zero Trust model should guide the design of the system, with explicit verification, least-privilege access, and the assumption of breach as key principles.</p> <p>Security is not a one-time effort but requires continuous improvement to keep up with evolving threats. The design principles should guide the security of the architecture, design choices, and operational processes. </p> <p>Failure to apply these principles can have a negative impact on business operations and revenue. Security and reliability can sometimes conflict, so trade-offs need to be carefully considered. By following these principles, security effectiveness can be improved, workload assets can be hardened, and trust can be built with users.</p>"},{"location":"security/#security-design-principles","title":"Security Design Principles","text":"<p>Here are some key security design principles for Microsoft's Well-Architected Framework:</p> <ul> <li> <p>Principle of Least Privilege: Each component of the system should have only the permissions it needs to perform its function and no more. This limits the potential damage if a component is compromised.</p> </li> <li> <p>Defense in Depth: Security should be implemented at multiple levels, not just at the perimeter. This includes network security, application security, and data security.</p> </li> <li> <p>Fail Securely: In the event of a failure, the system should default to a secure state, not an insecure one.</p> </li> <li> <p>Separation of Duties: Different responsibilities should be handled by different individuals or systems. This can prevent a single point of failure and limit the potential for insider threats.</p> </li> <li> <p>Security by Design: Security should be considered from the outset, not bolted on as an afterthought. This includes secure coding practices, threat modeling, and regular security reviews.</p> </li> <li> <p>Continuous Monitoring and Improvement: Security is not a one-time task but an ongoing process. Regular monitoring and auditing can help detect and respond to threats, and the security posture should be continually improved over time.</p> </li> </ul>"},{"location":"security/#llm-application-security","title":"LLM Application Security","text":"<ul> <li>OWASP Top 10 for LLM Applications<ul> <li>llmtop10</li> </ul> </li> <li>Azure Security Best Practices for LLM Applications</li> <li>Azure: AI in box, Guidance: Security for Generative AI (GenAI) Applications</li> </ul>"},{"location":"security/#cloud-native-security","title":"Cloud Native Security","text":"<ul> <li>OWASP Top 10 for Cloud Native Applications</li> <li>Azure Security Best Practices for Cloud Native Applications</li> <li>.NET: Azure security for cloud-native apps</li> <li>Azure: Well-Architected Framework - Security</li> </ul>"},{"location":"well-architected-framework/","title":"Well-architected Intelligent Apps","text":"<p>When evaluating Intelligent Apps, it's common to conduct a proof of concept (PoC), which can be completed relatively quickly. This often leads to a misconception that Intelligent Apps are easy to build and can be made production-ready in just a few days. However, this is far from the truth. To prepare intelligent applications for production, several factors need to be considered. These considerations are modeled around the Well-Architected Frameworks provided by major cloud providers<sup>1</sup> <sup>2</sup> <sup>3</sup>.</p> <p>Pillars of the Well-Architected Framework for Intelligent Applications:</p> <ul> <li> <p> Security</p> <p>Robust measures to protect information, systems, and assets, delivering business value through risk assessments and mitigation strategies.</p> </li> <li> <p> Responsible AI</p> <p>Guardrails, practices, &amp; principles to keep your use of AI ethical and trusted by your organization and users.</p> </li> <li> <p> Reliability</p> <p>Assurances in application code, infrastructure, and operations. Including at the Evaluation &amp; testing, both at the application, model, and data level. </p> </li> <li> <p> Operational Excellence</p> <p>Applying DevOps practices to achieve workload quality, process efficiency, and customer satisfaction.</p> </li> <li> <p> Performance Efficiency</p> <p>How well your intelligent app adapts to varying demands and optimizes its resources and capacity.</p> </li> <li> <p> Cost Optimization</p> <p>Aligning business goals, ROI, and financial constraints with a cost-optimized strategy.</p> </li> <li> <p> Sustainability</p> <p>Environmental impacts, especially energy consumption and efficiency to reduce resource usage.</p> </li> </ul> <p>Organizations can make this easier on development teams of Intelligent Apps by investing to platform engineering techniques that can lead a Internal Developer Platform (IDP) to produce better Intelligent Apps, faster.</p>"},{"location":"well-architected-framework/#what-is-the-well-architected-framework","title":"What is the Well-Architected Framework?","text":"<p>The Well-Architected Framework is a set of guiding tenets that can be used to improve the quality of a system. It provides a consistent approach for customers and partners to evaluate architectures, and provides guidance to help implement designs that will scale with application needs over time. The framework is based on five or six pillars \u2014 operational excellence, security, reliability, performance efficiency, cost optimization, and sustainability (depending on the hyper-scaler). It provides a set of questions that allows you to understand if a specific architecture aligns well with cloud best practices.</p> <p>We have added the additional pillar of Responsible AI, which is a set of guardrails, practices, and principles to keep your use of AI ethical and trusted by your organization and users.</p>"},{"location":"well-architected-framework/#applying-the-well-architected-framework-to-intelligent-apps","title":"Applying the Well-Architected Framework to Intelligent Apps","text":"<p>The Well-Architected Framework is not only applicable to traditional applications but also to Intelligent Apps. The addition of the Responsible AI pillar further enhances its relevance to Intelligent Apps. Here's how each pillar applies:</p> <ul> <li> <p>Security: Ensuring the privacy and protection of data is paramount in Intelligent Apps. This includes data used for training AI models and the data generated by these models.</p> </li> <li> <p>Responsible AI: This new pillar is particularly relevant to Intelligent Apps. It involves ensuring that AI models are transparent, fair, reliable, and safe. It also includes considerations for the ethical implications of AI.</p> </li> <li> <p>Reliability: Intelligent Apps must be reliable in their performance and predictions. This involves robust testing and validation of AI models.</p> </li> <li> <p>Performance Efficiency: Intelligent Apps should be designed to efficiently use resources and adapt to changes in demand. This includes the efficient use of computational resources for training and inference.</p> </li> <li> <p>Cost Optimization: Like any application, Intelligent Apps should be cost-effective. This involves optimizing the costs associated with data storage, computation, and other resources.</p> </li> <li> <p>Operational Excellence: Applying DevOps practices to AI development processes can help ensure the quality and efficiency of Intelligent Apps.</p> </li> <li> <p>Sustainability: Intelligent Apps should be designed with consideration for their environmental impact. This includes the energy used for training and running AI models.</p> </li> </ul> <p>By considering these pillars during the development of Intelligent Apps, organizations can ensure they are building high-quality, ethical, and efficient applications.</p>"},{"location":"well-architected-framework/#well-architected-review","title":"Well-architected Review","text":"<p>A Well-Architected Review is a systematic approach to evaluating systems based on the principles of the Well-Architected Framework. It involves assessing an application or system against the pillars of the framework, identifying areas for improvement, and implementing remediation plans to enhance the system's quality, performance, and reliability.</p> <p>Here are the link to the Well-Architected Frameworks for Azure: Azure Well-Architected Review.</p>"},{"location":"well-architected-framework/#tradeoff-between-the-pillars","title":"Tradeoff between the Pillars","text":"<p>The Well-Architected Framework is designed to help organizations make informed decisions about their architectures. However, it's important to recognize that there are trade-offs between the pillars. For example, optimizing for cost may involve trade-offs with reliability or performance efficiency. Similarly, optimizing for security may involve trade-offs with cost or operational excellence.</p> <p>By understanding these trade-offs, organizations can make informed decisions about how to balance the pillars based on their specific requirements and constraints. This can help them build Intelligent Apps that are well-architected and aligned with their business goals.</p>"},{"location":"well-architected-framework/#conclusion","title":"Conclusion","text":"<p>The Well-Architected Framework provides a valuable set of guiding tenets for building high-quality applications. By applying these principles to Intelligent Apps, organizations can ensure that they are building reliable, secure, scalable, cost-effective, and ethical AI applications. This can help them deliver value to customers and stakeholders while minimizing risk and ensuring compliance with best practices and principles.</p> <ol> <li> <p>Azure Well-Architected Framework \u21a9</p> </li> <li> <p>AWS Well-Architected Framework \u21a9</p> </li> <li> <p>Google Cloud Architecture Framework \u21a9</p> </li> </ol>"},{"location":"what-is-an-intelligent-app/","title":"What is an Intelligent App?","text":"<p>An Intelligent App is an application that utilizes artificial intelligence (AI) capabilities and is designed to fully leverage the benefits of the cloud computing delivery model. These applications are built and hosted directly on the cloud, designed to accommodate rapid change, large scale, and resilience.</p> <p> </p> <p>Intelligent Apps can adapt and learn from data inputs, thereby improving their performance and accuracy over time. They can process vast amounts of data, identify patterns, make predictions, and even make decisions. This makes them particularly useful in scenarios where human-like cognition needs to be emulated or where decisions need to be made in real-time.</p> <p>Gartner</p> <p>By 2026, 30% of new applications will use AI to drive personalized adaptive user interfaces, up from less than 5% today.</p> <p> source</p>"},{"location":"what-is-an-intelligent-app/#types-of-intelligent-apps","title":"Types of Intelligent Apps","text":"<p>There are several types of Intelligent Apps, including but not limited to:</p> <ul> <li> <p>Recommendation Systems: These apps analyze user behavior and preferences to provide personalized recommendations. They are commonly used in e-commerce and streaming platforms.</p> </li> <li> <p>Predictive Analytics Tools: These apps use historical data to predict future outcomes. They are often used in finance, healthcare, and marketing.</p> </li> <li> <p>Natural Language Processing (NLP) Systems: These apps can understand, interpret, and generate human language. They are used in chatbots, voice assistants, and sentiment analysis tools.</p> </li> <li> <p>Image and Video Analysis Apps: These apps can analyze and interpret visual data. They are used in surveillance systems, image recognition tools, and medical imaging.</p> </li> <li> <p>Autonomous Machines: These apps can perform tasks without human intervention. They are used in self-driving cars, drones, and robotics.</p> </li> </ul> <p>These applications are transforming industries by delivering enhanced customer experience, improving decision-making, and optimizing operations.</p>"},{"location":"what-is-an-intelligent-app/#benefits-of-an-intelligent-application","title":"Benefits of an Intelligent Application","text":"<p>Intelligent Applications offer numerous benefits, including: </p> <ul> <li> <p>Improved Decision Making: By analyzing vast amounts of data and identifying patterns, Intelligent Apps can provide insights that help in making informed decisions.</p> </li> <li> <p>Enhanced User Experience: Intelligent Apps can personalize the user experience by understanding and predicting user behavior, leading to increased user satisfaction and engagement. </p> </li> <li> <p>Increased Efficiency: Through automation and optimization of processes, Intelligent Apps can significantly increase operational efficiency.</p> </li> <li> <p>Scalability: Being cloud-native, these applications can easily scale up or down based on demand, providing cost-effectiveness and flexibility.</p> </li> <li> <p>Resilience: Intelligent Apps are designed to be resilient and can handle failures without significant impact on the user experience or performance.</p> </li> <li> <p>Continuous Learning and Adaptation: Intelligent Apps learn from every interaction, improving their performance and accuracy over time.</p> </li> </ul>"},{"location":"what-is-an-intelligent-app/#cons-of-an-intelligent-application","title":"Cons of an Intelligent Application","text":"<p>Despite the numerous benefits, there are also some potential drawbacks to consider when developing an Intelligent Application:</p> <ul> <li> <p>Complexity: The development and maintenance of Intelligent Apps can be complex due to the need for specialized knowledge in areas such as machine learning and data science.</p> </li> <li> <p>Data Privacy: Intelligent Apps often rely on large amounts of data, which can raise concerns about data privacy and security.</p> </li> <li> <p>Dependence on Quality Data: The performance of Intelligent Apps is heavily dependent on the quality of the data they are trained on. Poor quality data can lead to inaccurate predictions or decisions.</p> </li> <li> <p>Cost: While cloud-native applications can scale to reduce costs, the resources required for processing large amounts of data and running complex algorithms can be expensive.</p> </li> <li> <p>Ethical Considerations: The use of AI and machine learning can raise ethical questions, such as bias in decision-making processes and the potential for misuse of technology.</p> </li> </ul>"},{"location":"ai-feature-ideas/feature-idea-overview/","title":"AI Feature Ideas Overview","text":"<ul> <li> <p> UI</p> <p>Ideas for UI features/ improvements that can be added to your Intelligent App.</p> <p> View</p> </li> </ul>"},{"location":"ai-feature-ideas/ui-feature-ideas/","title":"UI Feature Ideas","text":"Title Description Smart Paste Smart Paste is an intelligent app feature that fills out forms automatically using data from the user's clipboard. You can use this with any existing form in your web app.  Smart ComboBox A combo box is a UI input element that allows users to type a value and to select a predefined value from an autocompleting dropdown. Traditional combo boxes suggest values only based on exact substring matches. Smart ComboBox upgrades this by suggesting semantic matches (i.e., options with the most closely related meanings). This is much more helpful for users who don't know/remember the exact predefined string they are looking for.  Smart Text Area Smart TextArea is an AI upgrade to the traditional textarea. It provides suggested autocompletions to whole sentences based on its configuration and what the user is currently typing."},{"location":"blog/","title":"Blog","text":""},{"location":"blog/2024/04/01/chunking-markdown-files-into-azure-ai-search-for-enable-rag/","title":"Chunking markdown files into Azure AI Search","text":"<p>Documentation in software development is a curial part of the software development process. Alot of the time the development documentation is written in markdown files which is what most of my professional documentation is written in but also what this blog and intelligentappfactory.com website. Giving AI/ Vectoring search capabilities to this content can bring a whole new level life to the documentation which can allow the intended audience to find the information they need quicker and easier than ever before.</p> <p>In this post we will:</p> <ul> <li>Explore Azure AI search and how it can be used to vector/ semantic search markdown files.</li> <li>Possible uses for indexed markdown files in Azure AI search.</li> <li>How to process markdown files into useable chunks into Azure AI search Index.</li> <li>The python code to process markdown files into chunks and upload to Azure AI search index. </li> </ul>","tags":["Azure AI Search","AI","Vector Databases","Python","Markdown","RAG","Intelligent Assistant"]},{"location":"blog/2024/04/01/chunking-markdown-files-into-azure-ai-search-for-enable-rag/#the-problem","title":"The problem","text":"<p>Developers and users of software applications often need to find information quickly and efficiently. This can be difficult when the information is spread across multiple markdown files, each containing a large amount of text. Having an intelligent Assistant that can answer questions and surface relevant information can help users find the information they need. The first part of the solution is to store these files in way that can be easily search and then utilized by an intelligent assistant (AI orchestrator) to present the information to the user. This is where Azure AI search comes in.</p>","tags":["Azure AI Search","AI","Vector Databases","Python","Markdown","RAG","Intelligent Assistant"]},{"location":"blog/2024/04/01/chunking-markdown-files-into-azure-ai-search-for-enable-rag/#azure-ai-search","title":"Azure AI Search","text":"<p>Azure AI Search is a cloud-based search-as-a-service solution that gives developers the ability to build powerful search capabilities into their applications. It provides a range of features, including full-text search, faceted navigation, and custom ranking. Azure AI Search also supports semantic search, which uses machine learning to understand the intent behind a user's query and deliver more relevant results. For this post will are going to focus on the vector store and vector/hybrid search capabilities of Azure AI search:</p> <ul> <li>Index: A collection of searchable documents that are organized into fields. Each field contains a specific piece of information about the document, such as its title, author, content, or vector embedding.</li> <li>Document: A single item in the index that represents a piece of content, such as a markdown file test or part of time. Each document is made up of a set of fields that contain information about the content.</li> <li>Indexer: A process that reads data from a data source, such as a database or file system, and creates documents in an index based on that data. Indexers can be scheduled to run at regular intervals to keep the index up to date with the data source.</li> <li>Query: A request for information from the index. Queries can be simple keyword searches or more complex queries that use filters, facets, and other search features.</li> <li>Vector Search: A search technique that uses vector embeddings to find similar documents based on their semantic meaning. Vector search can be used to find documents that are similar to a given query document or to find documents that are similar to each other.</li> <li>Hybrid Search: A search technique that combines keyword search with vector search to deliver more relevant results. Hybrid search can be used to find documents that match a user's query while also taking into account the semantic meaning of the query.</li> <li>Semantic Ranking: A ranking technique that uses machine learning to understand the intent behind a user's query and deliver more relevant results. Semantic ranking can be used to boost the relevance of documents that are similar to the user's query or to demote documents that are not relevant to the user's query.</li> </ul>","tags":["Azure AI Search","AI","Vector Databases","Python","Markdown","RAG","Intelligent Assistant"]},{"location":"blog/2024/04/01/chunking-markdown-files-into-azure-ai-search-for-enable-rag/#solution-architecture","title":"Solution Architecture","text":"<p>The ideal solution architecture for this project is shown in the diagram below:</p> <ol> <li>The markdown files are stored in an Git repository where developers commit their documentation to main branch.</li> <li>An Github Actions or Azure Pipeline will be triggered which will run a python script used to process the files in useable chunks and upload them to an Azure AI Search index.</li> <li>Azure AI Search will turn the content of each chunk into an vector embedding using Azure OpenAI's text-embedding-ada-002 or text-embedding-ada-003-large model.</li> <li>The Azure AI Search index is then used to power a search interface that allows users to find information in the markdown files. The search interface can be integrated into an intelligent assistant or other application to provide users with quick and easy access to the information they need. Allowing application to perform RAG (Retrieval Augmented Generation) on the indexed markdown files which could be used to provide a chat interface to the documentation.</li> </ol> <p></p> <p>For this post we will be focusing on using python to process the markdown files into chunks and upload them to an Azure AI Search index locally which at a later date can be integrated into a CI/CD pipeline of the described architecture. </p>","tags":["Azure AI Search","AI","Vector Databases","Python","Markdown","RAG","Intelligent Assistant"]},{"location":"blog/2024/04/01/chunking-markdown-files-into-azure-ai-search-for-enable-rag/#why-manually-index-markdown-files","title":"Why manually index markdown files?","text":"<p>The reason for manually indexing the markdown files is to allow for more control over the indexing process. This can be useful when you want to index only certain parts of the markdown files, such as code snippets or headings, or when you want to apply custom processing to the content before indexing it. </p> <p>Manually indexing the markdown files also allows you to experiment with different indexing strategies and see how they affect the search results. When trying using indexer with integrated vectorization or chunking the markdown files into the index, the results can be less than optimal are the solution required more control over the indexing process with the chunking of the markdown files via their headings and subheadings but also increased information in metadata and searchable/ filterable fields in the index.</p>","tags":["Azure AI Search","AI","Vector Databases","Python","Markdown","RAG","Intelligent Assistant"]},{"location":"blog/2024/04/01/chunking-markdown-files-into-azure-ai-search-for-enable-rag/#python-script-features","title":"Python Script features","text":"<p>The python script will have the following features:</p> <ul> <li>Chunking: The python script will chunk the markdown files into smaller pieces based on the headings and subheadings in the files (up to 3 levels of headings). This will allow the content to be indexed more granularly and make it easier to find specific information in the files.</li> <li>Metadata: The python script will extract metadata from the markdown files, such as the title, author, and date, and store it in the Azure AI Search index. This will allow users to filter and sort the search results based on this information.</li> <li>Vectorization: The python script will use Azure OpenAI's text-embedding-ada-002 or text-embedding-ada-003-large model to generate vector embeddings for the content of the markdown files.</li> <li>Indexing: The python script will upload the content, metadata, and vector embeddings to an Azure AI Search index.</li> <li>Run many times: The python script can be run multiple times to update the index with new content or changes to existing content. This will keep the index up to date with the markdown files in the repository. Deleting the content which does not need updating is not supported in this version of the script.</li> </ul>","tags":["Azure AI Search","AI","Vector Databases","Python","Markdown","RAG","Intelligent Assistant"]},{"location":"blog/2024/04/01/chunking-markdown-files-into-azure-ai-search-for-enable-rag/#fields-in-the-azure-ai-search-index","title":"Fields in the Azure AI Search Index","text":"<p>The fields in the Azure AI Search index will be used to store information about the content of the markdown files. The fields will include the following:</p> <ul> <li>id: A unique identifier for the document.</li> <li>title: The title of the document.</li> <li>content: The content of the document.</li> <li>metadata: Additional information about the document e.g. heading information.</li> <li>uri: The URI of the document. e.g. GitHub URL or hosted page URL.</li> <li>repository: The repository where the document is stored.</li> <li>path: The path to the document in the repository.</li> <li>source: The source of the document.</li> <li>updated: The date the document was last updated.</li> <li>chunk_number: The number of the chunk in the document.</li> </ul>","tags":["Azure AI Search","AI","Vector Databases","Python","Markdown","RAG","Intelligent Assistant"]},{"location":"blog/2024/04/01/chunking-markdown-files-into-azure-ai-search-for-enable-rag/#python-script","title":"Python Script","text":"<p>The python script will be used to process the markdown files and upload them to an Azure AI Search index. </p> <p>The script will be run locally and will require the following dependencies to be installed:  - azure-search-documents  - azure-identity  - langchain_community  - langchain_openai  - langchain_text_splitters  - python-dotenv  - python-frontmatter  - markdown</p> <p>Note</p> <p>The full code for the python script can be found in the Intelligent App Factory Solutions repository</p>","tags":["Azure AI Search","AI","Vector Databases","Python","Markdown","RAG","Intelligent Assistant"]},{"location":"blog/2024/04/01/chunking-markdown-files-into-azure-ai-search-for-enable-rag/#environment-variables-cli-arguments","title":"Environment variables &amp; cli arguments","text":"<p>The python script will require the following environment variables to be set: .env<pre><code>#Azure Open AI\nAZURE_OPENAI_ENDPOINT=\"https://{{instancename}}.openai.azure.com/\" # Azure Open AI Endpoint\nAZURE_OPENAI_API_KEY=\"Azure Open AI Key\" # Azure Open AI Key\nAZURE_OPENAI_API_VERSION=\"2023-05-15\" # Azure Open AI API Version\nAZURE_DEPLOYMENT=\"text-embedding-ada-002\" # Azure Deployment name for ADA Model could be text-embedding-ada-002 or text-embedding-ada-003-large\n\n# Azure Search\nVECTOR_STORE_ADDRESS=\"https://{{instancename}}.search.windows.net\" # Azure AI Search Endpoint\nVECTOR_STORE_PASSWORD=\"Azure Search Key\" #Azure AI Search Key\nINDEX_NAME=\"index-name\" # Azure AI Search Index Name\n</code></pre> Cli arguments for the python script: <pre><code>python __main__.py --repository org/repo --directory docs\n</code></pre></p>","tags":["Azure AI Search","AI","Vector Databases","Python","Markdown","RAG","Intelligent Assistant"]},{"location":"blog/2024/04/01/chunking-markdown-files-into-azure-ai-search-for-enable-rag/#solution-files","title":"Solution files","text":"<p>The python script will be split into the following files:</p> <ul> <li><code>__main__.py</code>: The main entry point for the script.</li> <li><code>importer.py</code>: A module that contains the main orchestrator that controllers the full process to call all other modules.</li> <li><code>markdown_parser.py</code>: A module that contains functions for parsing and chunks markdown files as well as retrieving metadata.</li> <li><code>vector_search.py</code>: A module that contains functions for uploading chunked markdown file and its metadata to the Azure AI Search index.</li> <li><code>document_manager.py</code>: A module that contains functions for managing the documents in the index including delete.</li> </ul>","tags":["Azure AI Search","AI","Vector Databases","Python","Markdown","RAG","Intelligent Assistant"]},{"location":"blog/2024/04/01/chunking-markdown-files-into-azure-ai-search-for-enable-rag/#code-snippets","title":"Code Snippets","text":"__main__.py<pre><code>import sys\nimport argparse\nfrom dotenv import load_dotenv, dotenv_values\nimport logging\nfrom document_importer.importer import Importer\n\n\ndef main(args: list = sys.argv) -&gt; None:\n    logging.info(\"Starting the document importer...\")\n    logging.info(\"-----------------Starting Script-----------------\")\n    # Parse the arguments\n    parser = argparse.ArgumentParser()\n    parser.add_argument('-r', '--repository', help='The github repository name', required=True)\n    parser.add_argument('-d', '--directory', help='The directory of the markdown documents', required=True)\n    parser.add_argument('-l', '--loglevel', default='warning',\n                        help='Provide logging level. Example --loglevel debug, default=warning')\n    args = parser.parse_known_args(args)\n\n    logging.basicConfig(level=args[0].loglevel.upper(), format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\")\n    # Load the environment variables\n    load_dotenv(override=True)\n    config = {\n        **dotenv_values(),\n    }\n    print(f\"Imported configuration of length: {len(config.keys())}\")\n    print(f\"Args: {args}\")\n    Importer(config, repository=args[0].repository, directory=args[0].directory).run()\n\n    logging.info(\"-----------------Script Completed-----------------\")\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre> importer.py<pre><code>import os\nimport logging\nfrom document_importer.vector_search import VectorSearch\nfrom document_importer.markdown_parser import MarkdownParser\nfrom document_importer.document_manager import DocumentManager\n\n\nclass Importer:\n    def __init__(self, config: dict, repository: str, directory: str) -&gt; None:\n        \"\"\"\n        Initializes an instance of the Importer class.\n        Args:\n            config (dict): The configuration dictionary.\n            repository (str): The repository name.\n            directory (str): The directory path.\n        \"\"\"\n        # Load the environment variables\n        self.config: dict = config\n        # Verify the environment variables\n        self.__check_environment_variable(\"AZURE_OPENAI_ENDPOINT\")\n        self.__check_environment_variable(\"AZURE_OPENAI_API_KEY\")\n        self.__check_environment_variable(\"AZURE_OPENAI_API_VERSION\")\n        self.__check_environment_variable(\"AZURE_DEPLOYMENT\")\n        self.__check_environment_variable(\"VECTOR_STORE_ADDRESS\")\n        self.__check_environment_variable(\"VECTOR_STORE_PASSWORD\")\n        self.__check_environment_variable(\"INDEX_NAME\")\n        # Set the parameters\n        self.vector_search = VectorSearch(config)\n        self.document_manager = DocumentManager(config)\n        self.markdown_parser = MarkdownParser()\n        self.directory: str = directory\n        self.repository: str = repository\n        self.chunk_size: int = 1000\n        self.chunk_overlap: int = 0\n        self.failed_files: list[str] = []\n        self.succeed_files: list[str] = []\n        self.total_chunks: int = 0\n        self.succeed_cleaning: int = 0\n        self.file_paths: list[str] = []\n\n    def run(self) -&gt; None:\n        \"\"\"\n        Runs the import process.\n        \"\"\"\n        # Get all the markdown files\n        logging.info(\"-----------------Getting Markdown Files-----------------\")\n        self.file_paths = list(self.__get_all_files(self.directory))\n        logging.info(f\"Found {len(self.file_paths)} markdown files in directory {self.directory}...\")\n        logging.info(f\"Files: {self.file_paths}\")\n        logging.info(\"-----------------Getting Pre-import Statistics-----------------\")\n        self.pre_import_index_stats = self.document_manager.get_document_store_statistics()\n        logging.info(\"-----------------Starting Importing Files-----------------\")\n        for file_path in self.file_paths:\n            try:\n                logging.info(f\"Loading document {self.repository}:{file_path}...\")\n                docs = self.markdown_parser.parse(file_path, repository=self.repository,\n                                                  chunk_size=self.chunk_size, chunk_overlap=self.chunk_overlap)\n                page_contents = docs.get(\"page_contents\")\n                page_metadatas = docs.get(\"page_metadatas\")\n                if self.document_manager.clean_document(self.repository, file_path):\n                    self.succeed_cleaning += 1\n                self.vector_search.load_chunks(page_contents, page_metadatas)\n                self.succeed_files.append(file_path)\n                self.total_chunks += len(page_contents)\n            except Exception as e:\n                logging.error(f\"Failed to load document {file_path}: {str(e)}\")\n                self.failed_files.append(file_path)\n        logging.info(\"-----------------Importing files completed-----------------\")\n        logging.info(\"-----------------Getting Post-import Statistics-----------------\")\n        self.post_import_index_stats = self.__report_result(self.pre_import_index_stats)\n\n    def __report_result(self, pre_import_index_stats):\n        \"\"\"\n        Reports the import result.\n        Args:\n            pre_import_index_stats: The pre-import index statistics.\n        \"\"\"\n        if len(self.failed_files) &gt; 0:\n            print(f\"Failed to load {len(self.failed_files)}/{len(self.file_paths)}\")\n            logging.debug(f\"Failed files load a total of {self.failed_files} markdown files.\")\n        if len(self.succeed_files) &gt; 0:\n            print(f\"Succeed to load {len(self.succeed_files)}/{len(self.file_paths)} markdown files \"\n                  + f\"with a total of {self.total_chunks} chunks \"\n                  + f\"and successful cleaned up {self.succeed_cleaning} older markdown files (if present).\")\n            logging.debug(f\"Succeed files: {self.succeed_files}\")\n        self.document_manager.get_document_store_statistics(pre_import_index_stats)\n\n    def __check_environment_variable(self, environment_variable: str) -&gt; None:\n        if not self.config.get(environment_variable):\n            raise ValueError(f\"Required environment variable {environment_variable} is not set\")\n\n    def __get_all_files(self, directory):\n        for dirpath, dirnames, filenames in os.walk(directory):\n            for filename in filenames:\n                if os.path.splitext(filename)[1] == '.md':\n                    yield os.path.join(dirpath, filename)\n</code></pre> markdown_parser.py<pre><code>import frontmatter\nfrom langchain_text_splitters import RecursiveCharacterTextSplitter, MarkdownHeaderTextSplitter\nfrom datetime import datetime\nfrom frontmatter import Post\n\n\nclass MarkdownParser:\n    def __init__(self):\n        pass\n\n    def parse(self, path: str, encoding: str = \"utf-8\",\n              chunk_size: int = 1000, chunk_overlap: int = 0, repository: str = \"\") -&gt; dict:\n        # Load the documents\n        markdown_document = self.__load_markdown_document(path)\n\n        # MD splits\n        splits = self.__spilt_markdown_document(chunk_size, chunk_overlap, markdown_document)\n\n        return self.__format_chunks(splits, metadata=markdown_document, repository=repository, path=path)\n\n    def __spilt_markdown_document(self, chunk_size, chunk_overlap, markdown_document) -&gt; list:\n        headers_to_split_on = [\n            (\"#\", \"Header 1\"),\n            (\"##\", \"Header 2\"),\n            (\"###\", \"Header 3\"),\n        ]\n        markdown_splitter = MarkdownHeaderTextSplitter(\n            headers_to_split_on=headers_to_split_on, strip_headers=False\n        )\n        md_header_splits = markdown_splitter.split_text(markdown_document.content)\n\n        # Recursive character text splitter\n        text_splitter = RecursiveCharacterTextSplitter(\n            chunk_size=chunk_size, chunk_overlap=chunk_overlap\n        )\n\n        # Split\n        splits = text_splitter.split_documents(md_header_splits)\n        return splits\n\n    def __load_markdown_document(self, path: str) -&gt; Post:\n        markdown_document = frontmatter.load(path)\n        if len(markdown_document.keys()) == 0:\n            raise ValueError(f\"No frontmatter found in the markdown document at {path}...\")\n        if not markdown_document.get(\"title\") or markdown_document.get(\"title\").strip() == \"\":\n            raise ValueError(f\"No title found in the frontmatter of the markdown document at {path}...\")\n        if not markdown_document.get(\"summary\") or markdown_document.get(\"summary\").strip() == \"\":\n            raise ValueError(f\"No summary found in the frontmatter of the markdown document at {path}...\")\n        if not markdown_document.get(\"uri\") or markdown_document.get(\"uri\").strip() == \"\":\n            raise ValueError(f\"No uri found in the frontmatter of the markdown document at {path}...\")\n        if markdown_document.get(\"authors\") is None or markdown_document.get(\"authors\") == []:\n            raise ValueError(f\"No authors found in the frontmatter of the markdown document at {path}...\")\n        return markdown_document\n\n    def __format_chunks(self, chunks, metadata, repository: str, path: str) -&gt; dict:\n        page_metadatas = []\n        page_contents = []\n        today = datetime.utcnow().strftime(\"%Y-%m-%dT%H:%M:%S-00:00\")\n        chunk_number: int = 0\n        for chunk in chunks:\n            chunk_number += 1\n            page_metadatas.append({\n                    \"title\": metadata.get(\"title\"),\n                    \"source\": path,\n                    \"uri\": metadata.get(\"uri\"),\n                    \"repository\": repository,\n                    \"path\": path,\n                    \"summary\": metadata.get(\"summary\"),\n                    \"authors\": metadata.get(\"authors\"),\n                    \"last_update\": today,\n                    \"heading\": chunk.metadata,\n                    \"chunk_number\": chunk_number,\n                }\n            )\n            page_contents.append(chunk.page_content)\n\n        return {\n            \"page_metadatas\": page_metadatas,\n            \"page_contents\": page_contents,\n        }\n</code></pre> vector_search.py<pre><code>from langchain_community.vectorstores.azuresearch import AzureSearch\nfrom langchain_openai import AzureOpenAIEmbeddings\nfrom langchain_community.document_loaders import TextLoader\nfrom langchain_text_splitters import CharacterTextSplitter\nfrom azure.search.documents.indexes.models import (SearchableField,SearchField,SearchFieldDataType,SimpleField,)\nimport logging\n\n\nclass VectorSearch:\n    \"\"\"\n    A class for performing vector-based search using Azure OpenAI and Azure Search.\n    \"\"\"\n\n    def __init__(self, config: dict = {}):\n        # Azure OpenAI\n        azure_endpoint: str = config.get(\"AZURE_OPENAI_ENDPOINT\")\n        azure_openai_api_key: str = config.get(\"AZURE_OPENAI_API_KEY\")\n        azure_openai_api_version: str = config.get(\"AZURE_OPENAI_API_VERSION\")\n        azure_deployment: str = config.get(\"AZURE_DEPLOYMENT\")\n\n        # Azure Search\n        vector_store_address: str = config.get(\"VECTOR_STORE_ADDRESS\")\n        vector_store_password: str = config.get(\"VECTOR_STORE_PASSWORD\")\n        index_name: str = config.get(\"INDEX_NAME\")\n\n        # Initialize the Azure OpenAI Embeddings\n        self.embeddings: AzureOpenAIEmbeddings = AzureOpenAIEmbeddings(\n            azure_deployment=azure_deployment,\n            openai_api_version=azure_openai_api_version,\n            azure_endpoint=azure_endpoint,\n            api_key=azure_openai_api_key,\n        )\n        logging.info(f\"Embeddings initialized : {azure_deployment} (endpoint), {azure_deployment} (deployment)\")\n\n        # Initialize the Azure Search Vector Store\n        self.vector_store: AzureSearch = AzureSearch(\n            azure_search_endpoint=vector_store_address,\n            azure_search_key=vector_store_password,\n            index_name=index_name,\n            embedding_function=self.embeddings.embed_query,\n            fields=self.__index_fields()\n        )\n        logging.info(f\"Vector store initialized: {vector_store_address} (endpoint), {index_name} (index)\")\n\n    def search(self, query: str, k: int = 3, search_type: str = \"similarity\", filters: str = None):\n        return self.vector_store.similarity_search(query=query, k=k, search_type=search_type, filters=filters)\n\n    def load_documents(self, path: str, encoding: str = \"utf-8\", chunk_size: int = 1000, chunk_overlap: int = 0):\n        print(\"Loading documents: {path}\")\n        loader = TextLoader(path, encoding=encoding)\n\n        documents = loader.load()\n        text_splitter = CharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n        docs = text_splitter.split_documents(documents)\n\n        self.vector_store.add_documents(documents=docs)\n\n    def load_chunks(self, page_contents: list, page_metadatas: list):\n        self.vector_store.add_texts(page_contents, page_metadatas)\n\n    def __index_fields(self):        \n        fields = [\n            SimpleField(\n                name=\"id\",\n                type=SearchFieldDataType.String,\n                key=True,\n                filterable=True,\n            ),\n            SearchableField(\n                name=\"content\",\n                type=SearchFieldDataType.String,\n                searchable=True,\n            ),\n            SearchField(\n                name=\"content_vector\",\n                type=SearchFieldDataType.Collection(SearchFieldDataType.Single),\n                searchable=True,\n                vector_search_dimensions=len(self.embeddings.embed_query(\"Text\")),\n                vector_search_profile_name=\"myHnswProfile\",\n            ),\n            SearchableField(\n                name=\"metadata\",\n                type=SearchFieldDataType.String,\n                searchable=True,\n            ),\n            # Additional field to store the title\n            SearchableField(\n                name=\"title\",\n                type=SearchFieldDataType.String,\n                searchable=True,\n            ),\n            # Additional field for filtering on document source\n            SimpleField(\n                name=\"source\",\n                type=SearchFieldDataType.String,\n                filterable=True,\n            ),\n            # Additional data field for last doc update\n            SimpleField(\n                name=\"last_update\",\n                type=SearchFieldDataType.DateTimeOffset,\n                searchable=True,\n                filterable=True,\n            ),\n            # Additional data field for last doc update\n            SimpleField(\n                name=\"uri\",\n                type=SearchFieldDataType.String,\n                searchable=True,\n                filterable=True,\n            ),\n            SimpleField(\n                name=\"repository\",\n                type=SearchFieldDataType.String,\n                searchable=True,\n                filterable=True,\n            ),\n            SimpleField(\n                name=\"summary\",\n                type=SearchFieldDataType.String,\n                searchable=True,\n            ),\n        ]\n        return fields\n</code></pre> document_manager.py<pre><code>from ast import Dict, List\nfrom azure.core.credentials import AzureKeyCredential\nfrom azure.search.documents import SearchClient, SearchItemPaged\nfrom azure.search.documents.indexes import SearchIndexClient\nimport logging\n\n\nclass DocumentManager:\n    def __init__(self, config):\n        self.service_endpoint = config.get(\"VECTOR_STORE_ADDRESS\")\n        self.index_name = config.get(\"INDEX_NAME\")\n        key = config.get(\"VECTOR_STORE_PASSWORD\")\n        credential = AzureKeyCredential(key)\n        self.search_client = SearchClient(self.service_endpoint, self.index_name, credential)\n        self.index_client = SearchIndexClient(self.service_endpoint, credential)\n\n    def get_full_document(self, repository: str, source: str) -&gt; SearchItemPaged[Dict]:\n        filter = f\"repository eq '{repository}' and source eq '{source}'\"\n        return self.search_client.search(search_text=\"*\", filter=filter, top=1000)\n\n    def clean_document(self, repository: str, source: str) -&gt; int:\n        logging.info(f\"Cleaning documents for {repository}:{source}...\")\n        # Getting documents from index\n        chunks = self.get_full_document(repository, source)\n        data_list: List[Dict] = []\n        [data_list.append(chunk) for chunk in chunks]\n        if len(data_list) == 0:\n            logging.info(f\"No documents found for {repository}: {source}\")\n            return True\n        # Deleting documents from index\n        results = self.search_client.delete_documents(data_list)\n        return self.__report_clean(repository, source, data_list, results)\n\n    def get_document_store_statistics(self, oldStats: Dict = None) -&gt; Dict:\n        logging.info(f\"Getting statistics for index {self.index_name}...\")\n        result: Dict = self.index_client.get_index_statistics(self.index_name)\n        log: str = f\"Statistics for index {self.index_name} retrieved: {result}\"\n        if oldStats is not None:\n            log += f\" old stats: {oldStats}\"\n        print(log)\n        return result\n\n    def __report_clean(self, repository, source, data_list, results):\n        failed_to_delete: int = 0\n        succeeded_to_delete: int = 0\n        for result in results:\n            if result.succeeded is False:\n                failed_to_delete += 1\n            else:\n                succeeded_to_delete += 1\n        if failed_to_delete &gt; 0:\n            logging.warning(f\"Failed to delete {failed_to_delete}/{len(data_list)} for {repository}:{source}\")\n        logging.info(f\"Succeeded to delete {succeeded_to_delete}/{len(data_list)} in {repository}:{source}\")\n        return failed_to_delete == 0\n\n    def delete_vector_index(self, index: str):\n        self.index_client.delete_index(index)\n</code></pre>","tags":["Azure AI Search","AI","Vector Databases","Python","Markdown","RAG","Intelligent Assistant"]},{"location":"blog/2024/04/01/chunking-markdown-files-into-azure-ai-search-for-enable-rag/#conclusion","title":"Conclusion","text":"<p>In this post, we have explored how to chunk markdown files into smaller pieces and upload them to an Azure AI Search index using a python script. We have also discussed the benefits of manually indexing markdown files and the features of the python script. This post is part of a series of posts on how to enable RAG (Retrieval Augmented Generation) on data sources to enable intelligent assistants to provide a chat interface to the documentation. The next post will cover how to use the Azure AI Search index to power an intelligent assistant that can answer questions and provide information from the indexed markdown files. </p> <p>Note</p> <p>The full code for the python script can be found in the Intelligent App Factory Solutions repository</p>","tags":["Azure AI Search","AI","Vector Databases","Python","Markdown","RAG","Intelligent Assistant"]},{"location":"cloud-hyperscalers/aws/aws-intelligent-app-stack/","title":"AWS Intelligent App Stack","text":"<p>Amazon Web Services (AWS) is a subsidiary of Amazon providing on-demand cloud computing platforms and APIs to individuals, companies, and governments, on a metered pay-as-you-go basis. AWS offers a wide range of services including computing, storage, databases, analytics, networking, AI, and IoT. AWS provides create options for building, deploying, and managing intelligent applications through its global network of data centers.</p> <p>Here is the AWS Intelligent Application Stack:</p> <p></p>"},{"location":"cloud-hyperscalers/aws/aws-intelligent-app-stack/#ai","title":"AI","text":"Category Service Description Documentation Models Mistral AI LLMs created by Mistral AI for advanced AI modeling Link Models Meta AI models developed by Meta e.g. Llama 2 Link Models Amazon Titan High-performing foundation models from Amazon Link Models Hugging Face Open source AI Models Link Models Deci AI Simplify and accelerate the development of computer vision, Generative AI, and NLP applications with advanced tools to build, optimize, and deploy accurate and highly efficient models. Link"},{"location":"cloud-hyperscalers/aws/aws-intelligent-app-stack/#data","title":"Data","text":"Category Services Description Documentation Managed Databases DynamoDB Fully managed NoSQL database service Link Managed Databases Aurora Fully managed MySQL and PostgreSQL-compatible relational database Link Managed Databases ElastiCache Fully managed in-memory data store and cache service Link Storage Simple Storage Service (S3) Scalable object storage service Link Analytics Amazon Redshift Fully managed, petabyte-scale data warehouse service Link Analytics Event Bridge Serverless event bus service Link"},{"location":"cloud-hyperscalers/aws/aws-intelligent-app-stack/#compute","title":"Compute","text":"Category Service Description Documentation AI Orchestration Semantic Kernel AI orchestration SDK for .NET, Java, &amp; Python Link AI Orchestration LangChain AI orchestration SDK for Python, &amp; JavaScript Link AI Orchestration Llama Index LlamaIndex, Data Framework for LLM Applications Link Cloud Native Platform Amazon Elastic Container Service (ECS) Fully managed container orchestration service Link Cloud Native Platform Amazon Elastic Kubernetes Service (EKS) Managed Kubernetes service Link Cloud Native Platform Lambda Serverless compute service Link Cloud Native Platform AWS Fargate Serverless compute engine for containers Link Cloud Native Community Kubernetes Open-source system for automating deployment, scaling, and management of containerized applications Link Cloud Native Community Dapr Event-driven, portable runtime for building microservices Link Cloud Native Community Helm The package manager for Kubernetes Link Cloud Native Community KEDA Kubernetes-based event-driven autoscaling component Link Secrets &amp; Config App Config Service that centralizes app configuration and feature settings Link Secrets &amp; Config Key Management Service Service for securely storing and accessing secrets Link"},{"location":"cloud-hyperscalers/aws/aws-intelligent-app-stack/#integration","title":"Integration","text":"Category Service Description Documentation Integration Amazon Simple Queue Service (SQS) Fully managed message queuing service Link Integration Amazon Simple Notification Service (SNS) Fully managed pub/sub messaging service Link Integration Amazon API Gateway Fully managed API gateway service Link"},{"location":"cloud-hyperscalers/aws/aws-intelligent-app-stack/#observability","title":"Observability","text":"Category Service Description Documentation Observability Azure Monitor Full stack monitoring service for applications and infrastructure Link Observability Azure Application Insights Application performance management service for developers and DevOps professionals Link Observability Azure Managed Grafana Fully managed Grafana service for visualizing real-time analytics Link Observability Azure Managed Prometheus Fully managed Prometheus service for monitoring system metrics Link"},{"location":"cloud-hyperscalers/aws/aws-intelligent-app-stack/#development-tools","title":"Development Tools","text":"Category Service Description Documentation DevOps Tools GitHub Platform for version control and collaboration Link DevOps Tools AWS CodeArtifact Fully managed software artifact repository service Link DevOps Tools AWS CodeBuild Fully managed build service Link DevOps Tools AWS CodeCommit Fully managed source control service Link DevOps Tools AWS CodeDeploy Automated deployment service Link DevOps Tools AWS CodePipeline Fully managed continuous integration and continuous delivery service Link DevOps Tools AWS CloudFormation Infrastructure as Code tool for building, changing, and versioning infrastructure Link DevOps Tools Terraform Infrastructure as Code tool for building, changing, and versioning infrastructure Link DevOps Tools Powershell Task automation and configuration management framework Link DevOps Tools Management Console Web-based user interface for accessing and managing AWS services Link DevOps Tools Amazon Elastic Container Registry (ECR) Fully managed container registry service Link IDEs Visual Studio Code Free source-code editor made by Microsoft Link Copilots Amazon CodeWhisperer AI-powered code completion tool Link Programming Languages .NET Programming language that supports development of IA Link Programming Languages Java Programming language that supports development of IA Link Programming Languages Python Programming language that supports development of IA Link Programming Languages JS/NodeJS Programming language that supports development of IA Link"},{"location":"cloud-hyperscalers/azure/azure-cosmos-db/","title":"Azure Cosmos DB for Intelligent Applications","text":"<p>Azure Cosmos DB is a globally distributed, multi-model database service for building modern applications. It enables you to build highly responsive and always-on applications that can scale globally. Azure Cosmos DB provides turnkey global distribution across any number of Azure regions by transparently scaling and replicating your data wherever your users are. It offers comprehensive service level agreements (SLAs) for latency, throughput, consistency, and availability, backed by the most comprehensive set of compliance certifications in the industry.</p>"},{"location":"cloud-hyperscalers/azure/azure-cosmos-db/#key-links","title":"Key Links","text":"<ul> <li>Azure Cosmos DB documentation</li> <li>Using Azure Cosmos DB with LangChain</li> <li>Azure Cosmos DB Semantic Cache</li> <li>Azure Cosmos DB with Semantic Kernel</li> <li>Azure Cosmos DB Solution Accelerators for .NET</li> <li>Azure Cosmos DB Solution Accelerators for Java</li> </ul>"},{"location":"cloud-hyperscalers/azure/azure-intelligent-app-stack/","title":"Azure Intelligent App Stack","text":"<p>Azure is a cloud computing platform and infrastructure created by Microsoft. The platform offers a wide range of services including computing, storage, databases, analytics, networking, AI, and IoT. Azure provides create options for building, deploying, and managing intelligent applications through its global network of data centers.</p> <p>Here is the Azure Intelligent Application Stack:</p> <p></p> <p>Video Overview of the Azure Intelligent App Stack:</p>"},{"location":"cloud-hyperscalers/azure/azure-intelligent-app-stack/#ai","title":"AI","text":"Category Service Description Documentation Models Mistral AI LLMs created by Mistral AI for advanced AI modeling Link Models Meta AI models developed by Meta e.g. Llama 2 Link Models Azure Open AI Open source AI models provided by Azure e.g. GPT4 Link Models Hugging Face Open source AI Models Link Models Deci AI Simplify and accelerate the development of computer vision, Generative AI, and NLP applications with advanced tools to build, optimize, and deploy accurate and highly efficient models. Link Models NVIDIA NVIDIA AI Foundation Models Link Models Microsoft Research Cutting-edge AI models from Microsoft Research Link AI Services Azure Cognitive Services Suite of AI services and cognitive APIs to help developers build intelligent applications Link AI Services Azure Machine Learning Service that provides a cloud-based environment you can use to develop, train, test, deploy, manage, and track machine learning models Link AI Services Azure AI Studio Build cutting-edge, market-ready, responsible applications for your organization with AI Link AI Services Azure AI Search AI-powered cloud search service for mobile and web app development Link"},{"location":"cloud-hyperscalers/azure/azure-intelligent-app-stack/#data","title":"Data","text":"Category Services Description Documentation Managed Databases Azure Cosmos DB Globally distributed, multi-model database service Link Managed Databases Azure SQL Family Fully managed relational database with auto-scale, integral intelligence, and robust security Link Managed Databases Postgres Fully managed, intelligent, and flexible PostgreSQL relational database service Link Managed Databases Azure Cache for Redis Fully managed, open source-compatible in-memory data store to power fast, scalable applications Link Storage Azure Storage Account Durable, highly available, and massively scalable cloud storage Link Analytics Azure Synapse Analytics Analytics service that brings together enterprise data warehousing and Big Data analytics Link Analytics Azure Event Hubs Big data streaming platform and event ingestion service Link"},{"location":"cloud-hyperscalers/azure/azure-intelligent-app-stack/#compute","title":"Compute","text":"Category Service Description Documentation AI Orchestration Semantic Kernel AI orchestration SDK for .NET, Java, &amp; Python Link AI Orchestration LangChain AI orchestration SDK for Python, &amp; JavaScript Link AI Orchestration Llama Index LlamaIndex, Data Framework for LLM Applications Link Cloud Native Platform Azure Container Apps Fully managed service for running containerized apps Link Cloud Native Platform Azure App Service Fully managed platform for building, deploying, and scaling web apps Link Cloud Native Platform Azure Functions Event-driven, serverless compute platform Link Cloud Native Platform Azure Kubernetes Managed Kubernetes service for deploying, managing, and scaling containerized applications Link Cloud Native Community Kubernetes Open-source system for automating deployment, scaling, and management of containerized applications Link Cloud Native Community Dapr Event-driven, portable runtime for building microservices Link Cloud Native Community Helm The package manager for Kubernetes Link Cloud Native Community KEDA Kubernetes-based event-driven autoscaling component Link Secrets &amp; Config Azure App Configuration Service that centralizes app configuration and feature settings Link Secrets &amp; Config Azure Key Vault Service for securely storing and accessing secrets Link"},{"location":"cloud-hyperscalers/azure/azure-intelligent-app-stack/#integration","title":"Integration","text":"Category Service Description Documentation Integration Azure Service Bus Fully managed enterprise message broker with message queues and publish-subscribe topics Link Integration Azure Event Grid Fully managed event routing service Link Integration Azure API Management Turnkey solution for publishing APIs to external and internal customers Link"},{"location":"cloud-hyperscalers/azure/azure-intelligent-app-stack/#observability","title":"Observability","text":"Category Service Description Documentation Observability Azure Monitor Full stack monitoring service for applications and infrastructure Link Observability Azure Application Insights Application performance management service for developers and DevOps professionals Link Observability Azure Managed Grafana Fully managed Grafana service for visualizing real-time analytics Link Observability Azure Managed Prometheus Fully managed Prometheus service for monitoring system metrics Link"},{"location":"cloud-hyperscalers/azure/azure-intelligent-app-stack/#development-tools","title":"Development Tools","text":"Category Service Description Documentation DevOps Tools GitHub Platform for version control and collaboration Link DevOps Tools Azure DevOps Services for teams to share code, track work, and ship software Link DevOps Tools Terraform Infrastructure as Code tool for building, changing, and versioning infrastructure Link DevOps Tools Powershell Task automation and configuration management framework Link DevOps Tools Bicep Infrastructure as Code tool for deploying infrastructure Azure resources Link DevOps Tools Azure Container Registry Managed Docker registry service for storing and managing container images Link IDEs Visual Studio Code Free source-code editor made by Microsoft Link IDEs Visual Studio 2022 Integrated development environment from Microsoft Link Copilots GitHub Copilot AI-powered code completion tool Link Copilots Microsoft Copilot for Azure AI-powered tool for Azure services Link Programming Languages .NET Programming language that supports development of IA Link Programming Languages Java Programming language that supports development of IA Link Programming Languages Python Programming language that supports development of IA Link Programming Languages JS/NodeJS Programming language that supports development of IA Link"},{"location":"concepts/ai-charters/","title":"AI Charters","text":"<p>An AI Charter is a document that outlines the principles and guidelines for AI use within an organization. It is developed collaboratively with employees and serves as a roadmap for how an organization or project plans to use or interact with AI technologies. The Charter acts as a constitution for AI, setting the stage for responsible and ethical AI usage. It reflects the unique culture, goals, and ethical considerations of the organization, and helps anticipate and mitigate potential risks associated with AI integration.</p>"},{"location":"concepts/ai-charters/#why-your-organization-needs-an-ai-charter","title":"Why Your Organization Needs an AI Charter","text":""},{"location":"concepts/ai-charters/#anticipating-ai-adoption","title":"Anticipating AI Adoption","text":"<p>Even if your organization has not yet adopted AI, creating an AI Charter can stimulate meaningful conversations about what AI integration could mean for your business. It's an engaging activity that can help you envision the future of your organization with AI.</p>"},{"location":"concepts/ai-charters/#establishing-principles-and-values","title":"Establishing Principles and Values","text":"<p>Your AI Charter should be unique, reflecting your organization's distinct culture, goals, and ethical considerations. While there may be common elements like data privacy and security requirements, the Charter should be customized to your organization's specific needs and values.</p>"},{"location":"concepts/ai-charters/#mitigating-risks","title":"Mitigating Risks","text":"<p>AI integration can introduce unique risks, some of which you may not have anticipated. These could range from data security and privacy compliance issues, to ethical concerns about biased AI outputs, and potential legal risks related to intellectual property, such as copyright infringement. An AI Charter can help you foresee these challenges and devise strategies to mitigate them.</p>"},{"location":"concepts/ai-charters/#good-example-of-ai-charters","title":"Good example of AI Charters","text":"MicrosoftOpen AIGoogleCapgemini <p>Microsoft's AI Charter is a great example. It outlines six principles that guide their use of AI:</p> <ol> <li>Fairness: Microsoft commits to ensuring that its AI systems treat all people fairly.</li> <li>Reliability and Safety: Microsoft will take robust steps to ensure the reliability and safety of its AI systems.</li> <li>Privacy and Security: Microsoft is committed to protecting the privacy and security of its customers' data.</li> <li>Inclusiveness: Microsoft's AI systems will be designed to empower everyone and engage people.</li> <li>Transparency: Microsoft will be transparent about how its AI systems work and will provide meaningful explanations about its AI systems' decisions.</li> <li>Accountability: Microsoft will be accountable for upholding these principles and will take appropriate action if its AI systems do not adhere to them.</li> </ol> <p>This AI Charter serves as a guiding document for Microsoft's AI initiatives, ensuring that they are not only technologically advanced but also ethically responsible.</p> <p> source</p> <p>OpenAI's AI Charter is another great example. It outlines the following principles:</p> <ol> <li>Broadly distributed benefits: AI should benefit all of humanity.</li> <li>Long-term safety: AI should be safe and secure.</li> <li>Technical leadership: AI should be developed in a way that is aligned with human values.</li> <li>Cooperative orientation: AI should be used to complement and empower humans.</li> <li>Recursive self-improvement: AI should be developed in a way that allows for recursive self-improvement.</li> </ol> <p>These principles guide OpenAI's use of AI and ensure that their AI systems are developed and used responsibly.</p> <p> source</p> <p>Google's AI Principles are another example. They include the following:</p> <ol> <li>Be socially beneficial.</li> <li>Avoid creating or reinforcing unfair bias.</li> <li>Be built and tested for safety.</li> <li>Be accountable to people.</li> <li>Incorporate privacy design principles.</li> <li>Uphold high standards of scientific excellence.</li> <li>Be made available for uses that accord with these principles.  </li> </ol> <p>These principles guide Google's use of AI and ensure that their AI systems are developed and used responsibly.  source</p> <p>Capgemini's Code of Ethics for AI is another example. It outlines the following principles:</p> <ol> <li>AI with carefully delimited impact: designed for human benefit, with a clearly defined purpose setting out what the solution will deliver, to whom.</li> <li>Sustainable AI: developed mindful of each stakeholder, to benefit the environment and all present and future members of our ecosystem, human and non-human alike, and to address pressing challenges such as climate change, CO\u2082 reduction, health improvement, and sustainable food production. 3 Fair AI: produced by diverse teams using sound data for unbiased outcomes and the inclusion of all individuals and population groups.</li> <li>Transparent and explainable AI: with outcomes that can be understood, traced and audited, as appropriate.</li> <li>Controllable AI with clear accountability: enabling humans to make more informed choices and keep the last say.</li> <li>Robust and safe AI: including fallback plans where needed.</li> <li>AI respectful of privacy and data protection: considering data privacy and security from the design phase, for data usage that is secure, and legally compliant with privacy regulations.</li> </ol> <p>These principles guide Capgemini's use of AI and ensure that their AI initiatives are not only technologically advanced but also ethically responsible.</p> <p> source</p>"},{"location":"concepts/ai-charters/#summary","title":"Summary","text":"<p>An AI Charter is a foundational document that sets the stage for responsible and ethical AI usage. It reflects the unique culture, goals, and ethical considerations of the organization or project, and helps anticipate and mitigate potential risks associated with AI integration. The Charter should be developed collaboratively with employees and should be tailored to the organization's specific needs and values. It should serve as a guiding document for AI initiatives, ensuring that they are not only technologically advanced but also ethically responsible.</p>"},{"location":"concepts/ai-model-evaluation/","title":"AI Model Evaluation","text":"<p>AI Test, Evaluation, Validation and Verification (TEVV) is a critical part of the AI development lifecycle. It is important to ensure that the AI model is performing as expected and is not biased. AI model evaluation is the process of evaluating the performance of an AI model on a given dataset. The evaluation process involves measuring the performance of the model on various metrics such as accuracy, precision, recall, F1 score, etc. The evaluation process also involves identifying and mitigating any biases present including harmful content in the model.</p> <p>My short AI definition for \"AI Model Evaluation\": tests and metrics used to evaluate the performance of an AI model on a given dataset to ensure production readiness.</p>"},{"location":"concepts/ai-model-evaluation/#frameworks-tooling","title":"Frameworks &amp; Tooling","text":"<p>There are several frameworks and tools available for AI model evaluation. Some of the popular frameworks and tools include:</p> <ul> <li>Azure AI Studio: Azure AI Studio is a cloud-based platform that provides a suite of tools for building, training, and deploying AI models. Azure AI Studio also provides tools for evaluating the performance of AI models. Work particularly well within the Azure ecosystem.</li> <li>Prompt Flow: Microsoft created tool for evaluating the performance of AI models. It provides a suite of tools for measuring the performance of AI models on various metrics. This is also integrated with Azure AI Studio.</li> <li>Amazon Bedrock: Amazon's tool for evaluating the performance of AI models. It provides a suite of tools for measuring the performance of AI models on various metrics. Good if you are in the AWS ecosystem and your models are deployed on AWS.</li> <li>Google's Vertex AI Studio: Google's tool for evaluating the performance of AI models. It provides a suite of tools for measuring the performance of AI models on various metrics. Good choice if you are in the GCP ecosystem.</li> <li>LangSmith: LangSmith is a tool for evaluating the performance of AI models. It provides a suite of tools for measuring the performance of AI models on various metrics. It is a good choice if you are looking for a tool that is not tied to a specific cloud provider and can be free for a single developer but has a cost for teams.</li> <li>TruLens: Open-source tool with high transparency and expandability. It provides a suite of tools for measuring the performance of AI models on various metrics. It is a good choice if you are looking for a tool that is not tied to a specific cloud provider and is free for all users.</li> <li>DeepEval: DeepEval is an open-source tool for evaluating the performance of AI models. It provides a suite of tools for measuring the performance of AI models on various metrics. It is a good choice if you are looking for a tool that is not tied to a specific cloud provider and is free for all users.</li> </ul>"},{"location":"concepts/ai-model-evaluation/#metrics","title":"Metrics","text":""},{"location":"concepts/ai-model-evaluation/#performance-quality-metrics","title":"Performance &amp; Quality Metrics","text":"<p>There are several metrics that are commonly used to evaluate the performance of AI models. Some of the popular metrics include: - Groundless: How well the model is grounded in the data. - Similarity: How similar the model's predictions are to a given dataset. - Accuracy: The percentage of correct predictions made by the model. - Relevance: - Coherence</p>"},{"location":"concepts/ai-model-evaluation/#risk-safety-metrics","title":"Risk &amp;  Safety Metrics","text":"<ul> <li>Content risk defect rate</li> <li>Jailbreak defect rate</li> </ul>"},{"location":"getting-started/learn-intelligent-apps/","title":"Learning Intelligent Apps","text":"<p>CLoud Native - Build Intelligent Apps</p> <p>Live Learn  - Intelligent Apps on AKS - 1  - Intelligent Apps with AKS - 2  - Microsoft Learn AI Skills Challenge</p>"},{"location":"programming-languages/dotnet/dotnet-overview/","title":".NET for Intelligent Apps","text":"<p>.NET is a powerful and versatile framework that provides a solid foundation for developing intelligent applications. With its rich ecosystem of libraries, tools, and language support, .NET enables developers to build AI-powered applications that can perform complex tasks like machine learning, natural language processing, and computer vision. Whether you are building chatbots, recommendation engines, predictive analytics, or other intelligent applications, .NET offers the capabilities and flexibility you need to bring your ideas to life.</p> <p>Here are a few reasons why .NET is a good option for intelligent app development:</p> <ul> <li>Wide Range of Libraries and Tools: .NET offers a rich ecosystem of libraries and tools that can be leveraged for building intelligent apps. For example, you can use libraries like ML.NET for machine learning tasks, TensorFlow.NET for deep learning, and Accord.NET for various data science and statistical operations. These libraries provide pre-built models, algorithms, and utilities that can accelerate the development process.</li> <li>Language Flexibility: .NET supports multiple programming languages, including C#, F#, and VB.NET. This allows developers to choose the language they are most comfortable with for building intelligent apps. C# is particularly popular for .NET development and offers a wide range of features and libraries for implementing machine learning and AI algorithms.</li> <li>Integration with Existing .NET Ecosystem: If you are already familiar with .NET development, leveraging the existing ecosystem can be a significant advantage. You can reuse existing code, libraries, and frameworks, which can save time and effort. Additionally, .NET integrates well with other Microsoft technologies, such as Azure, which provides a robust cloud platform for hosting and scaling intelligent applications.</li> <li>Performance and Scalability: .NET is known for its performance and scalability. It is designed to handle high loads and can efficiently process large amounts of data. This is crucial for intelligent apps that often involve complex computations and data processing. With .NET, you can build applications that can handle real-time data streams, perform complex analytics, and scale to meet growing demands.</li> <li>Cross-Platform Development: .NET Core, the open-source and cross-platform version of .NET, allows you to develop intelligent apps that can run on various platforms, including Windows, macOS, and Linux. This enables you to reach a wider audience and deploy your applications on different devices and environments.</li> <li>AI Capabilities: .NET provides several AI capabilities that can be used to build intelligent applications. For example, ML.NET is a machine learning framework that allows you to train and deploy machine learning models using C# and F#. It provides a simple and intuitive API for building predictive models, natural language processing tasks, and computer vision applications. Additionally, .NET offers integration with popular AI services like Azure Cognitive Services, Azure Machine Learning, and OpenAI, allowing you to leverage cloud-based AI capabilities in your applications.</li> <li>Microsoft &amp; Community Support: .NET is backed by Microsoft, which provides extensive documentation, tutorials, and support for developers. The .NET community is also active and vibrant, with many resources, forums, and events available for developers to learn and collaborate. This can be valuable when building intelligent apps, as you can get help, share knowledge, and stay up-to-date with the latest trends and best practices.</li> </ul> <p>Overall, .NET provides a robust and flexible platform for developing intelligent apps. It offers a wide range of libraries, language options, and integration capabilities, making it a great choice for building AI-powered applications.</p>"},{"location":"programming-languages/dotnet/dotnet-overview/#key-links","title":"Key Links","text":"<ul> <li>.NET Homepage: Learn more about the .NET platform and how to get started.</li> <li>.NET AI Homrpage: Explore the AI capabilities of .NET and how to build intelligent applications.</li> <li>.NET Community Standup: Watch the .NET AI Community Standup to learn more about the Semantic Kernel and other AI tools for .NET developers.</li> </ul>"},{"location":"programming-languages/dotnet/dotnet-overview/#libraries-frameworks-and-sdks","title":"Libraries, Frameworks, and SDKs","text":"<ul> <li> Semantic Kernel:      An open-source SDK for building agents that can call your existing code. Use it with models from OpenAI, Azure OpenAI, Hugging Face, and more! </li> <li> ASP.net Core:      Free. Cross-platform. Open source. A framework for building web apps and services with .NET and C#.</li> <li> Blazor:      Use the power of .NET and C# to build full stack web apps without writing a line of JavaScript.</li> </ul>"},{"location":"programming-languages/dotnet/dotnet-overview/#getting-started","title":"Getting Started","text":"<p>Learn more about .NET for intelligent apps and how to get started:</p> <ul> <li>.NET AI: Use these hand-picked resources to learn how to use .NET to build an amazing AI-infused application!</li> </ul>"},{"location":"programming-languages/dotnet/semantic-kernel/","title":"Semantic Kernel for .NET Intelligent Apps","text":"<p>Semantic Kernel is an open-source Software Development Kit (SDK) that lets you easily build agents that can call your existing code. As a highly extensible SDK, you can use Semantic Kernel with models from OpenAI, Azure OpenAI, Hugging Face, and more! By combining your existing C#, Python, and Java code with these models, you can build agents that answer questions and automate processes.</p>"},{"location":"programming-languages/dotnet/semantic-kernel/#key-links","title":"Key Links","text":"<ul> <li>Semantic Kernel Documentation: Learn how to use the Microsoft Semantic Kernel to build intelligent applications on the .NET platform.</li> <li>Semantic Kernel GitHub Repository: Contribute to the Microsoft Semantic Kernel on GitHub.</li> <li>Semantic Kernel Office Hour - Recordings: Watch the recordings of the Microsoft Semantic Kernel Office Hour sessions.</li> <li>Semantic Kernel Blog - Blog: Read the latest blog posts about the Microsoft Semantic Kernel.</li> <li>.NET AI Community Standup: Watch the .NET AI Community Standup to learn more about the Semantic Kernel and other AI tools for .NET developers.</li> </ul>"},{"location":"programming-languages/dotnet/semantic-kernel/#getting-started","title":"Getting Started","text":"<p>Learn more about the Semantic Kernel and how to use it in your .NET intelligent applications:</p> <ul> <li>Microsoft Learn path, APL-2005 Develop AI agents using Azure OpenAI and the Semantic Kernel SDK: Focused on how to use the Semantic Kernel SDK to build intelligent applications that automate tasks and perform natural language processing (more information).</li> </ul>"},{"location":"programming-languages/dotnet/semantic-kernel/#projects-and-samples-built-with-semantic-kernel","title":"Projects and samples built with Semantic Kernel","text":"<ul> <li>Project Miyagi: Reimagines the design, development, and deployment of intelligent applications on top of Azure with all of the latest AI services and tools.</li> </ul>"},{"location":"reference-architecture/azure/azure-architecture/","title":"Overview","text":"<p>Reference architecture designs for intelligent applications leveraging Azure Cloud. It outlines how various reference Architectures utilizing Azure services and tools to build robust, scalable, and intelligent applications. This reference architectures serves as a guide to understand the best practices and patterns for designing and deploying intelligent applications on Azure.</p>"},{"location":"reference-architecture/azure/azure-architecture/#reference-architecture","title":"Reference Architecture","text":"<ul> <li>Azure Architecture Center: Artificial intelligence (AI) architecture design</li> </ul>"},{"location":"blog/archive/2024/","title":"2024","text":""},{"location":"blog/category/first/","title":"first","text":""}]}